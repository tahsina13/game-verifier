{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "if iskaggle: \n",
    "    !pip install -Uqq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "from fastcore.all import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "USERNAME = os.getenv('REDDIT_USERNAME')\n",
    "PASSWORD = os.getenv('REDDIT_PASSWORD')\n",
    "APP_ID = os.getenv('APP_ID')\n",
    "APP_NAME = os.getenv('APP_NAME')\n",
    "APP_SECRET = os.getenv('APP_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_valid_gallery_url(url): \n",
    "    return isinstance(url, str) and re.match(r'https?://www.reddit.com/gallery/[a-z0-9]+', url)\n",
    "\n",
    "def get_gallery_id(url): \n",
    "    return url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official Reddit API, requires auth\n",
    "REDDIT_PUB_URL = 'https://www.reddit.com/'\n",
    "REDDIT_OUTH_URL = 'https://oauth.reddit.com/'\n",
    "\n",
    "\n",
    "def get_api_token():\n",
    "    data = {'grant_type': 'password',\n",
    "            'username': USERNAME, 'password': PASSWORD}\n",
    "    auth = requests.auth.HTTPBasicAuth(APP_ID, APP_SECRET)\n",
    "    r = requests.post(REDDIT_PUB_URL + 'api/v1/access_token',\n",
    "                      headers={'user-agent': f'{APP_NAME} by {USERNAME}'},\n",
    "                      data=data, auth=auth)\n",
    "    d = r.json()\n",
    "    return 'bearer ' + d['access_token']\n",
    "\n",
    "\n",
    "def get_posts_reddit(subreddit, token, **params):\n",
    "    headers = {'Authorization': token,\n",
    "               'User-Agent': f'{APP_NAME} by {USERNAME}'}\n",
    "    response = requests.get(\n",
    "        REDDIT_OUTH_URL + f'r/{subreddit}/new.json', headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        raise Exception(f'Request failed with status code {response.status_code}')\n",
    "\n",
    "\n",
    "def get_gallery_urls_reddit(subreddit, token, classes, limits=100, max_imgs=1000):\n",
    "    urls = [[] for _ in classes]\n",
    "    limits = list(limits) if hasattr(\n",
    "        limits, '__iter__') else [limits] * len(classes)\n",
    "    next_name = ''\n",
    "    while np.any([len(u) < l for u, l in zip(urls, limits)]):\n",
    "        posts = get_posts_reddit(subreddit, token, limit=100, after=next_name)\n",
    "        next_name = posts['after']\n",
    "        for post in posts['children']:\n",
    "            post = post['data']\n",
    "            label, url = post['link_flair_text'], post['url']\n",
    "            is_valid = is_valid_gallery_url(url)\n",
    "            gallery_data = post['gallery_data'] if 'gallery_data' in post else None\n",
    "            img_cnt = len(gallery_data['items']) if gallery_data else 0\n",
    "            if label in classes and is_valid and img_cnt <= max_imgs:\n",
    "                index = classes.index(label)\n",
    "                if len(urls[index]) < limits[index]:\n",
    "                    urls[index].append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thrid-party PullPush API, no auth\n",
    "PULLPUSH_URL = \"https://api.pullpush.io/reddit/search/submission/\"\n",
    "\n",
    "\n",
    "def get_posts_pullpush(subreddit, **kwargs):\n",
    "    params = {'subreddit': subreddit, **kwargs}\n",
    "    response = requests.get(PULLPUSH_URL, params=params)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_gallery_urls_pullpush(subreddit, classes, limits=100, max_imgs=1000):\n",
    "    urls = [[] for _ in classes]\n",
    "    limits = list(limits) if hasattr(\n",
    "        limits, '__iter__') else [limits] * len(classes)\n",
    "    cur_time = int(time.time())\n",
    "    while np.any([len(u) < l for u, l in zip(urls, limits)]):\n",
    "        posts = get_posts_pullpush(\n",
    "            subreddit, locked=True, size=100, before=cur_time)\n",
    "        if 'data' not in posts or not len(posts['data']):\n",
    "            break\n",
    "        for post in posts['data']:\n",
    "            cur_time = int(post['created_utc'])\n",
    "            label, url = post['link_flair_text'], post['url']\n",
    "            is_valid = is_valid_gallery_url(url)\n",
    "            gallery_data = post['gallery_data'] if 'gallery_data' in post else None\n",
    "            img_cnt = len(gallery_data['items']) if gallery_data else 0\n",
    "            if label in classes and is_valid and img_cnt <= max_imgs:\n",
    "                index = classes.index(label)\n",
    "                if len(urls[index]) < limits[index]:\n",
    "                    urls[index].append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = get_api_token()\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDIT = \"gameverifying\"\n",
    "CLASSES = ['Legitimate', 'Fake']\n",
    "LIMIT, MAX_IMAGES = 150, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Official Reddit API\n",
    "urls = get_gallery_urls_reddit(SUBREDDIT, token, CLASSES, LIMIT, MAX_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Third-party Pullpush API\n",
    "urls = get_gallery_urls_pullpush(SUBREDDIT, CLASSES, LIMIT, MAX_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls, links in zip(CLASSES, urls):\n",
    "    print(f'{cls}: {len(set(links))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def download_gallery_images(path, url):\n",
    "    path = Path(path)\n",
    "    id = get_gallery_id(url)\n",
    "    dirname = path / id\n",
    "    dirname.mkdir(exist_ok=True, parents=True)\n",
    "    commands = ['gallery-dl', url, '-D', dirname]\n",
    "    subprocess.run(commands, stdout=subprocess.DEVNULL,\n",
    "                   stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = Path('/kaggle/input' if iskaggle else '.')\n",
    "OUTPUT_DIR = Path('/kaggle/working' if iskaggle else '.')\n",
    "\n",
    "ROOT_DIR = INPUT_DIR / 'gameverifying-data' if iskaggle else INPUT_DIR\n",
    "DATA_DIR = ROOT_DIR / 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
    "for cls, links in zip(CLASSES, urls): \n",
    "    path = DATA_DIR / cls.lower()\n",
    "    parallel(partial(download_gallery_images, path), set(links), progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_image_files(DATA_DIR)\n",
    "failed = verify_images(fnames)\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "def get_gallery_dirs(root): \n",
    "    return np.concatenate([(root / cls.lower()).ls() for cls in CLASSES])\n",
    "\n",
    "gal_dirs = get_gallery_dirs(DATA_DIR)\n",
    "img_cnts = {d : len(get_image_files(d)) for d in gal_dirs}\n",
    "\n",
    "max_cnt = max(img_cnts.values())\n",
    "counter = Counter(img_cnts.values())\n",
    "\n",
    "labels = list(range(max_cnt + 1))\n",
    "freqs = list(map(counter.__getitem__, labels))\n",
    "\n",
    "plt.bar(labels, freqs)\n",
    "\n",
    "plt.title(\"Number of Images per Post\")\n",
    "plt.xlabel(\"Number of Images\")\n",
    "plt.ylabel(\"Number of Posts\")\n",
    "plt.xticks(labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cnts = sorted(img_cnts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "for dirname, cnt in top_cnts[:10]: \n",
    "    print(f'{str(dirname).ljust(25)}\\t{cnt}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates(ImagesCleaner)\n",
    "class GalleryCleaner(GetAttr):\n",
    "    def __init__(self, dirnames, **kwargs):\n",
    "        self.default = self.iw = ImagesCleaner(**kwargs)\n",
    "        self.dd_dnames = widgets.Dropdown(options=dirnames)\n",
    "        self.btn_select = widgets.Button(description='Select All')\n",
    "        self.btn_delete = widgets.Button(description='Delete')\n",
    "        self.dd_dnames.observe(self.on_change_dir, names='value')\n",
    "        self.btn_select.on_click(self.on_select_all)\n",
    "        self.btn_delete.on_click(self.on_delete_all)\n",
    "        self.on_change_dir()\n",
    "        self.widget = VBox([self.dd_dnames, self.iw.widget,\n",
    "                           self.btn_select, self.btn_delete])\n",
    "\n",
    "    def _ipython_display_(self): display(self.widget)\n",
    "\n",
    "    def on_change_dir(self, change=None):\n",
    "        fnames = sorted(get_image_files(self.dd_dnames.value))\n",
    "        self.iw.set_fns(fnames)\n",
    "\n",
    "    def on_select_all(self, btn): \n",
    "        for dd in L(self.iw.widget.children).itemgot(1): \n",
    "            dd.value = '<Delete>'\n",
    "\n",
    "    def on_delete_all(self, btn): \n",
    "        for idx in self.iw.delete(): \n",
    "            self.iw.fns[idx].unlink()\n",
    "        self.on_change_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = GalleryCleaner(L(top_cnts).itemgot(0))\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = list(map(shutil.rmtree, [d for d, c in img_cnts.items() if c == 0]))\n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_gallery(dirname):\n",
    "    dirname = Path(dirname)\n",
    "    fnames = sorted(get_image_files(dirname))\n",
    "    for i in range(len(fnames) // 2):\n",
    "        old_parent = fnames[2*i].parent\n",
    "        new_parent = old_parent.with_name(\n",
    "            f'{old_parent.name}_{i}') if i > 0 else old_parent\n",
    "        new_parent.mkdir(exist_ok=True)\n",
    "        shutil.move(fnames[2*i], new_parent / fnames[2*i].name)\n",
    "        shutil.move(fnames[2*i+1], new_parent / fnames[2*i+1].name)\n",
    "    if len(fnames) % 2 == 1:\n",
    "        fnames[-1].unlink()\n",
    "\n",
    "split = list(map(split_gallery, get_gallery_dirs(DATA_DIR)))\n",
    "len(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_gallery_images(dirname):\n",
    "    dirname = Path(dirname)\n",
    "    fnames = sorted(get_image_files(dirname))\n",
    "    for i in range(len(fnames)):\n",
    "        ext = fnames[i].suffix\n",
    "        fnames[i].rename(fnames[i].with_name(f'{(i+1):03}{ext}'))\n",
    "\n",
    "renamed = list(map(rename_gallery_images, get_gallery_dirs(DATA_DIR)))\n",
    "len(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in CLASSES: \n",
    "    cnt = len((DATA_DIR / cls.lower()).ls())\n",
    "    print(f'{cls}: {cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTuple(fastuple): \n",
    "    @classmethod\n",
    "    def create(cls, dirname, **kwargs): \n",
    "        return cls(tuple(PILImage.create(f, **kwargs) for f in sorted(get_image_files(dirname))))\n",
    "\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        t1, t2, *_ = self\n",
    "        if not isinstance(t1, Tensor) or not isinstance(t2, Tensor) or t1.shape != t2.shape: return ctx\n",
    "        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n",
    "        return show_image(torch.cat([t1,line,t2], dim=2), ctx=ctx, **kwargs)\n",
    "\n",
    "def ImageTupleBlock(): \n",
    "    return TransformBlock(type_tfms=ImageTuple.create, batch_tfms=IntToFloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = get_gallery_dirs(DATA_DIR)[0]\n",
    "img = Resize(224)(ImageTuple.create(dirname))\n",
    "tst = ToTensor()(img)\n",
    "tst.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    blocks=(ImageTupleBlock, CategoryBlock),\n",
    "    get_items=get_gallery_dirs,\n",
    "    splitter=RandomSplitter(valid_pct=0.2),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(480),\n",
    "    batch_tfms=aug_transforms(size=224),\n",
    ")\n",
    "\n",
    "@typedispatch\n",
    "def show_batch(x:ImageTuple, y, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n",
    "    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)\n",
    "    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    return ctxs\n",
    "\n",
    "dls = dblock.dataloaders(DATA_DIR)\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = OUTPUT_DIR / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerifierModel(nn.Module):\n",
    "    def __init__(self, arch, n_out=1, **kwargs):\n",
    "        super().__init__()\n",
    "        model = timm.create_model(arch, pretrained=True, num_classes=0, **kwargs)\n",
    "        self.encoder = TimmBody(model)\n",
    "        self.cfg = model.default_cfg\n",
    "        self.head = create_head(self.encoder.model.num_features * 2, n_out)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        x1, x2, *_ = xs\n",
    "        ftrs = torch.cat([self.encoder(x1), self.encoder(x2)], dim=1)\n",
    "        return self.head(ftrs)\n",
    "\n",
    "\n",
    "model = VerifierModel('resnet18', n_out=dls.c)\n",
    "norm_tfms = Normalize.from_stats(model.cfg['mean'], model.cfg['std'])\n",
    "dls.add_tfms([norm_tfms], 'after_batch')\n",
    "learn = Learner(dls, model, metrics=error_rate, model_dir=MODEL_DIR)\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, lr = 4, 3e-3\n",
    "learn.fine_tune(epochs, base_lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
